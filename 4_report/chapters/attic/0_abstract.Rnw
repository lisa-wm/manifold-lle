Storyline

\begin{itemize}
  \item Goal: present SS-LLE as a local, graph-based manifold learning method
  incorporating prior knowledge
  \item Step 0: define basic mathematical concepts required to understand
  argumentation (plus notation)
  \item Step 1: introduce idea of \textbf{isometry} (most basic: MDS)
  \item Step 2: introduce idea of \textbf{graph-based} models
  \begin{itemize}
    \item Achieve non-linearity
    \item Common structure: build graph $\rightarrow$ derive matrix as quadratic
    form over graph function $\rightarrow$ derive embedding from eigenvalue 
    problem 
    \item Most basic: ISOMAP (global, dense, convex)
  \end{itemize}
  \item Step 3: introduce idea of \textbf{locality}
  \begin{itemize}
    \item Relax global to local isometry
    \item Find sparse rather than dense matrices
    \item \textbf{Laplacian eigenmaps} as concept in which the others can be 
    generalized
    \begin{itemize}
      \item Define weighting scheme for neighborhood
      \item Use Laplacian to derive matrix
      \item Solve sparse eigenvalue problem
    \end{itemize}
  \end{itemize}
  \item Step 4: introduce \textbf{local linearity}
  \begin{itemize}
    \item \textbf{LLE} 
    \begin{itemize}
      \item Obtain weights via linear reconstructions
      \item Can be shown to approximate graph Laplacian (Belkin \& Niyogi 
      (2006)) 
    \end{itemize}
    \item \textbf{Hessian LLE}
    \begin{itemize}
      \item Replace Laplacian by Hessian
    \end{itemize}
  \end{itemize}
  \item Step 5: introduce \textbf{prior knowledge}
  \begin{itemize}
    \item \textbf{SS-LLE}
    \item Improve results by pre-specifying some manifold coordinates
  \end{itemize}
\end{itemize}





