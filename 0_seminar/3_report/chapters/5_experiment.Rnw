\subsection{Experimental Design}
\label{design}

% ------------------------------------------------------------------------------

\subsubsection{Sensitivity Analysis}
\label{sensitivity}

After discussing the underlying theory and potential challenges, SSLLE shall 
now be put to work.
Two separate sensitivity analyses study how variation in the amount and quality 
of prior information affects embedding quality.
The following chapters will lay out the scenarios and evaluation framework and 
then discuss the experiments' results.
\\

\textbf{Sensitivity analysis I: landmark coverage vs number of prior 
points.}
The first experiment pits the quality of landmark coverage against the number of 
landmarks, reflecting the presumption of optimal landmark choice dominating 
random and poor selection.
A higher number of prior points is generally expected to be beneficial.
This gives rise to the following axes of variation, out of whose cartesian 
product 18 different scenarios emerge (always assuming exact prior information):
\begin{tight_enumerate}
  \item Landmark coverage $\in \{ \text{poor}, \text{ random}, 
  \text{ maximum}\}$.
  \item Number of landmark points $\in \{2, 4, 6, 8, 10, 12\}$.
\end{tight_enumerate}

\textbf{Sensitivity analysis II: label noise vs number of prior 
points.}
In the second experiment, the case of inexact prior information shall be 
examined more closely by allowing a varying amount of label noise.
Coverage is kept at its optimal configuration.
In order to simulate inexact prior information, prior points' true coordinates 
are corrupted by Gaussian noise, such that $\tilde{\pv} = \pv + \bm{\epsilon}$ 
for $\pv \in \Y$.
$\bm{\epsilon} = (\epsilon_1, \epsilon_2, \dots, \epsilon_d)^T$ is a zero-mean 
noise variable with uncorrelated components.
Noise scales with the inherent variability of each dimension, such that 
$\epsilon_i \sim N(0, (\alpha \cdot s_i)^2)$, where $i \in \{1, 2, \dots, d \}$ 
and $s_i$ denotes empirical standard deviation in dimension $i$.
Variation is steered via the noise level $\alpha$.
With the supposition of more landmarks being able to compensate for noise to 
some extent, this yields another 24 scenarios\footnote{
Varying any of the parameters beyond the ranges examined here does not reveal 
any further
insights.
}:
\begin{tight_enumerate}
  \item Noise level $\alpha \in \{0.1, 0.5, 1.0, 3.0\}$. 
  \item Number of landmark points $\in \{2, 4, 6, 8, 10, 12\}$.
\end{tight_enumerate}

% ------------------------------------------------------------------------------

\subsubsection{Evaluation Framework}
\label{eval}

\textbf{Performance evaluation.}
Embedding quality is evaluated on the 
\hyperref[auc_rnx]{\textit{area under the $R_{NX}$ curve}}, 
$\text{AUC}(R_{NX})$, as proposed by \citet{kraemeretal2019}.
This metric assesses the degree to which neighborhood relations are preserved. 
The $R_{NX}$ curve results from a normalized count of points which, for all 
possible $k$, remain in the $k$-neighborhoods they form part of in the 
observation space \citep{kraemeretal2019}.
For a more detailed derivation, please refer to section \ref{auc_rnx} of the 
appendix.
Unsupervised learning tasks are notoriously hard to evaluate and manifold 
learning is no exception.
Although $\text{AUC}(R_{NX})$ is considered reasonably reliable, all results 
will therefore also be inspected visually, which is possible here thanks to the 
low dimensionality of the evaluation data.
\\

\textbf{Data.}
Experiments are mainly conducted on two synthetic data sets with 1,000 samples 
each.
The \textit{Swiss roll} data is a widely used 2-manifold resulting from 
rolling a rectangular patch of data up to a spiral-like shape and embedding it 
in $\R^3$.
A somewhat more complex structure results from bending that same rectangular 
patch to form an \textit{incomplete tire}, basically a hollow torus with a strip 
and a chunk cut out from the tube in longitudinal and cross-section, 
respectively.
Both manifolds are depicted in figure \ref{fig_swiss_tire_world}.
A third example, the so-called \textit{world data} consisting of 2,527 
observations, is employed for the concluding comparison 
in chapter \ref{comparison}.
It represents a simplified model of the Earth with five continents (merging 
Europe and Asia and omitting the poles).
Section \ref{synthetic_data} documents the precise construction of all three
manifolds.

\begin{figure}[H]
  \begin{subfigure}[c]{0.25\textwidth}
    \centering
    \includegraphics[trim = 70 30 60 40, clip, % left bottom right top
    width = 0.6\textwidth]{figures/swiss_roll}
  \end{subfigure}
  \begin{subfigure}[c]{0.25\textwidth}
    \centering
    \includegraphics[trim = 40 50 0 40, clip, % left bottom right top
    width = \textwidth]{figures/incomplete_tire}
  \end{subfigure}
  \begin{subfigure}[c]{0.25\textwidth}
    \centering
    \includegraphics[trim = 50 100 50 20, clip, % left bottom right top
    width = 0.9\textwidth]{figures/world_3d}
  \end{subfigure}
  \caption[Synthetic data for experimental studies]{
  \raggedright
  Synthetic data for experimental studies, including the Swiss roll 
  (\textit{left}), incomplete tire (\textit{middle}), and world 
  (\textit{right}) data sets.
  For construction details, see section \ref{synthetic_data} of the appendix.
  \textit{Source:} own representation.}
  \label{fig_swiss_tire_world}
\end{figure}

% ------------------------------------------------------------------------------

\subsection{Results}
\label{results}

% ------------------------------------------------------------------------------

\subsubsection{Sensitivity Toward Prior Point Location}
\label{landmarks}

\begin{minipage}[b]{0.4\textwidth}
  \textbf{Key variation.}
  Recall that scenarios in the first sensitivity analysis vary in the method of
  landmark coverage and the number of selected prior points.
  Figure \ref{fig_key_landmark} depicts this variation for the maximum case of 
  twelve landmarks, marking the selected points in the true embedding (which is 
  the same for both data sets, see section \ref{synthetic_data}).
  While poor and random coverage are identical for either example, optimal 
  coverage is not as it adapts prior point selection to the intrinsic manifold 
  structure.
\end{minipage}%
\begin{minipage}[b]{0.05\textwidth}
  \phantom{xxx}
\end{minipage}%
\begin{minipage}[b]{0.55\textwidth}
  \begin{figure}[H]
    \begin{subfigure}[c]{\textwidth}
      \centering
      \includegraphics[trim = 50 20 20 20, clip, % left bottom right top
      width = \textwidth]{figures/sensitivity_landmarks_key_swiss_roll}
      \caption{
      \raggedright
      Swiss roll data}
    \end{subfigure}
    \begin{subfigure}[c]{\textwidth}
      \centering
      \includegraphics[trim = 50 20 20 0, clip, % left bottom right top
      width = \textwidth]{figures/sensitivity_landmarks_key_incomplete_tire}
      \caption{
      \raggedright
      Incomplete tire data}
    \end{subfigure}
    \caption[Key variation in sensitivity analysis I]{
    \raggedright
    Poor (\textit{left}), random (\textit{middle}), and optimal 
    (\textit{right}) coverage for both data sets. \textit{Source:} own 
    representation.
    }
    \label{fig_key_landmark}
  \end{figure}
\end{minipage}

\vspace{0.3cm}

An important thing to note here is that the optimally selected points do not 
appear to actually cover the surface well: they mostly cluster on the fringes 
of the embedding.
This artifact must probably be attributed to the estimation of geodesic 
distance, for which the implementation relies on the \texttt{dimRed} 
package \citep{pkgdimred}.
When geodesic distances are imprecise, the maximum coverage approach loses much 
of its appeal.
As the underlying computation is also rather expensive, it is definitely worth 
considering to instead dedicate the budget to sampling a larger number of points 
at random.
\\

\textbf{Quantitative results.}
Performance evaluation reflects this observation.
Figure \ref{fig_auc_landmarks} illustrates how performance, as measured by 
$\text{AUC}(R_{NX})$, varies across the scenarios for both data sets.
Colorization ranges from red for worst-case performance to green for an optimal 
embedding.
Clearly, random selection performs best, which is not really surprising 
considering how it also achieves better coverage than the other two methods 
(figure \ref{fig_key_landmark}).
As expected, more landmarks tend to improve the embedding, but this effect 
saturates rather quickly -- apparently, a few known coordinates already provide 
sufficient guidance.

\begin{figure}[H]
  \includegraphics[trim = 0 0 0 0, clip, % left bottom right top
  width = \textwidth]{figures/sensitivity_landmarks_auc}
  \caption[Quantitative results for sensitivity analysis I]{
  \raggedright
  Quantitative results for method of landmark coverage vs number of prior 
  points. 
  $\text{AUC}(R_{NX})$ has been scaled to take on a minimum of 0 and maximum of
  1 in both figures for better visibility of differences.
  Original scales: Swiss roll -- $\text{AUC}(R_{NX}) \in [0.2655, 0.4086]$,
  incomplete tire -- $\text{AUC}(R_{NX}) \in [0.2772, 0.6231]$.
  \textit{Source:} own representation.
  }
  \label{fig_auc_landmarks}
\end{figure}

\newpage

\textbf{Qualitative results.}
As mentioned before, quantitative evaluation of manifold learning tasks is a 
difficult endeavor, so figures \ref{fig_emb_landmarks_swiss} and 
\ref{fig_emb_landmarks_tire} allow to cross-check the results with the actual 
embeddings (a full-page version of both may be found in section 
\ref{qual_results} of the appendix).
Indeed, visual analysis suggests that optimal coverage does not perform so badly
after all and might even be considered superior to the randomly selected prior 
points, particularly so for the Swiss roll data (figure 
\ref{fig_emb_landmarks_swiss}).
The picture is somewhat more balanced for the incomplete tire (figure 
\ref{fig_emb_landmarks_tire}).
Poor coverage fails entirely in both cases, no matter the number of landmarks.

\begin{figure}[H]
  \centering
  \includegraphics[trim = 40 0 0 0, clip, width = 0.9\textwidth]
  {figures/sensitivity_landmarks_qual_swiss_roll}
  \caption[Qualitative results for Swiss roll data in sensitivity analysis I]
  {\raggedright
  Qualitative results for Swiss roll data, evaluating method of landmark 
  coverage vs number of prior points.
  \textit{Source:} own representation.}
  \label{fig_emb_landmarks_swiss}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[trim = 40 0 0 20, clip, width = 0.9\textwidth]
  {figures/sensitivity_landmarks_qual_incomplete_tire}
  \caption[Qualitative results for incomplete tire data in sensitivity analysis 
  I]
  {\raggedright
  Qualitative results for incomplete tire data, evaluating method of landmark 
  coverage vs number of prior points.
  \textit{Source:} own representation.}
  \label{fig_emb_landmarks_tire}
\end{figure}

% ------------------------------------------------------------------------------

\subsubsection{Sensitivity Toward Label Noise}
\label{noise}

\begin{minipage}[b]{0.4\textwidth}
  \textbf{Key variation.}
  The key variation in the second part of the analysis occurs at the level of 
  label noise used to simulate inexact prior information.
  Note that the noise level $\alpha$, multiplied by the empirical standard 
  deviation in the respective dimension, steers only the potential amount of 
  noise. 
  The actual perturbation is stochastic.
  Its Gaussian nature signifies that realizations can be expected to fall within 
  a range of two standard deviations around the zero mean with a probability of 
  approximately 95 percent.
\end{minipage}%
\begin{minipage}[b]{0.05\textwidth}
  \phantom{xxx}
\end{minipage}%
\begin{minipage}[b]{0.55\textwidth}
  \begin{figure}[H]
    \begin{subfigure}[c]{\textwidth}
      \centering
      \includegraphics[trim = 50 20 0 10, clip, % left bottom right top
      width = \textwidth]{figures/sensitivity_noise_key_swiss_roll}
      \caption{
      \raggedright
      Swiss roll data}
    \end{subfigure}
    \begin{subfigure}[c]{\textwidth}
      \centering
      \includegraphics[trim = 50 20 0 0, clip, % left bottom right top
      width = \textwidth]{figures/sensitivity_noise_key_incomplete_tire}
      \caption{
      \raggedright
      Incomplete tire data}
    \end{subfigure}
    \caption[Key variation in sensitivity analysis II]{
    \raggedright
    Varying levels of noise exemplified at one prior point location.
    Semi-axes of ellipsoids indicate one standard deviation in the respective 
    direction.
    \textit{Source:} own 
    representation.
    }
    \label{fig_key_noise}
  \end{figure}
\end{minipage}

\vspace{0.3cm}

Figure \ref{fig_key_noise} illustrates the potential impact of noisy labels.
Over the range of candidate values for $\alpha$, the gray ellipsoid represents, 
for one point, the area within which its perturbed counterpart might end up if 
it is displaced by at most one standard deviation in each direction.
It becomes immediately clear how large $\alpha$ values hold a substantial risk 
of modifying prior points beyond recognition.
\\

\textbf{Quantitative results.}
The resulting $\text{AUC}(R_{NX})$ in figure \ref{fig_auc_noise} corroborates 
this observation.
Embedding quality deteriorates with increasing label noise, and a higher number 
of landmarks can only compensate for so much.
In fact, the stochasticity of perturbation means that adding more landmarks 
might even be harmful in this scenario, which is reflected by the non-monotonic 
behavior of $\text{AUC}(R_{NX})$ along the axis of prior point quantity.
This phenomenon should vanish if the actual noise level were kept constant 
across the number of landmarks.
In general, the simulated noise appears to have affected the Swiss roll 
embedding more severely. 

\begin{figure}[H]
  \includegraphics[trim = 0 0 0 0, clip, % left bottom right top
  width = \textwidth]{figures/sensitivity_noise_auc}
  \caption[Quantitative results for sensitivity analysis II]{
  \raggedright
  Quantitative results for noise level vs number of prior points. 
  $\text{AUC}(R_{NX})$ has been scaled to take on a minimum of 0 and maximum of
  1 in both figures for better visibility of differences.
  Original scales: Swiss roll -- $\text{AUC}(R_{NX}) \in [0.2720, 0.4167]$,
  incomplete tire -- $\text{AUC}(R_{NX}) \in [0.3171, 0.6172]$.
  \textit{Source:} own representation.
  }
  \label{fig_auc_noise}
\end{figure}

\newpage

\textbf{Qualitative results.}
Again, the actual embeddings are depicted below for visual inspection.
The minimum amount of two landmarks is insufficient in any case.
Above that, SSLLE embeds the incomplete tire (figure \ref{fig_emb_noise_tire}) 
fairly well for low levels of noise, while at least six prior points seem 
necessary to find an embedding of the Swiss roll that actually resembles the 
true one (figure \ref{fig_emb_noise_swiss}).
Even $\alpha = 1.0$ is apparently tolerable in some configurations, but beyond 
that, dimensionality reduction starts to fail altogether.

\begin{figure}[H]
  \centering
  \includegraphics[trim = 40 0 0 0, clip, width = 0.9\textwidth]
  {figures/sensitivity_noise_qual_swiss_roll}
  \caption[Qualitative results for Swiss roll data in sensitivity analysis II]
  {\raggedright
  Qualitative results for Swiss roll data, evaluating noise level vs number 
  of prior points.
  \textit{Source:} own representation.}
  \label{fig_emb_noise_swiss}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[trim = 40 0 0 20, clip, width = 0.9\textwidth]
  {figures/sensitivity_noise_qual_incomplete_tire}
  \caption[Qualitative results for incomplete tire data in sensitivity analysis 
  II]
  {\raggedright
  Qualitative results for incomplete tire data, evaluating noise level vs 
  number of prior points.
  \textit{Source:} own representation.}
  \label{fig_emb_noise_tire}
\end{figure}

% ------------------------------------------------------------------------------

\subsection{Concluding Comparison}
\label{comparison}

In the end, the experiments shall be concluded with a brief comparison between 
SSLLE and its algorithmic relatives, standard LLE and HLLE.
Implementation of the latter two is again based on the \texttt{dimRed} package, 
where the sole parameter required to specify is neighborhood size.
For a fair comparison, the same $k$ as deemed optimal by SSLLE has been used.
SSLLE takes the best-case configuration of maximum coverage and twelve 
landmarks.

Comparison on both the Swiss roll and the incomplete tire 
(figure \ref{fig_comp_swiss_tire}) shows that SSLLE is a 
strong contender against the other two methods.
LLE does not find a meaningful embedding in either case, while HLLE 
performs impressively on the Swiss roll data but fails to fully undo the bending 
of the incomplete tire transformation.

\begin{figure}[H]
  \begin{subfigure}{0.5\textwidth}
    % \centering
    \includegraphics[trim = 60 20 20 20, clip, width = 0.85\textwidth]
    {figures/comparison_swiss_roll}
    \caption[]{Swiss roll data}
    \label{fig_comp_swiss}
  \end{subfigure}
  \begin{subfigure}{0.5\textwidth}
    % \centering
    \includegraphics[trim = 60 20 20 20, clip, width = 0.85\textwidth]
    {figures/comparison_incomplete_tire}
    \caption[]{Incomplete data}
  \end{subfigure}
  \caption[Comparison of LLE, HLLE and SSLLE on Swiss roll and incomplete tire 
  data]
  {\raggedright
  Embeddings found by LLE (\textit{respective left}), HLLE 
  (\textit{respective middle}), and SSLLE (\textit{respective right}).
  \textit{Source:} own representation.}
  \label{fig_comp_swiss_tire}
\end{figure}

For the somewhat more complicated world data manifold (figure 
\ref{fig_comp_world}), which contains multiple disconnected components, 
results are even more striking. 

\begin{minipage}[b]{0.45\textwidth}
  LLE and HLLE fail utterly and collapse the entire manifold onto a few points 
  each.
  SSLLE, by contrast, produces an embedding that resembles the actual map of the 
  Earth fairly closely (the slightly colored background shall make the embedding 
  borders more easily visible).
  Note that 25 landmarks have been used this time to keep the share
  of prior points with respect to total observations at a constant level.
\end{minipage}%
\begin{minipage}[b]{0.05\textwidth}
  \phantom{xxx}
\end{minipage}%
\begin{minipage}[b]{0.5\textwidth}
  \begin{figure}[H]
    \centering
    \includegraphics[trim = 20 0 0 0, clip, width = \textwidth]
    {figures/comparison_world}
    \caption[Comparison of LLE, HLLE and SSLLE on world data]
    {\raggedright
    Embedding for the world data set found by LLE (\textit{left}), 
    HLLE (\textit{middle}), and SSLLE 
    (\textit{right}).
    \textit{Source:} own representation.}
    \label{fig_comp_world}
  \end{figure}
\end{minipage}